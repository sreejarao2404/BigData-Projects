{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a91ff708-8bd8-4f4a-93bb-25f4c7751279",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|TERRITORY|       Total_Sales|\n",
      "+---------+------------------+\n",
      "|     APAC| 746121.8300000002|\n",
      "|     EMEA|4979272.4099999955|\n",
      "|    Japan| 455173.2200000002|\n",
      "|       NA| 3852061.390000001|\n",
      "+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import sum\n",
    " \n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Sales Partitioning by Territory\") \\\n",
    "    .getOrCreate()\n",
    " \n",
    "sales_df = spark.read.csv(\"sales.csv\", header=True, inferSchema=True)\n",
    " \n",
    "sales_by_territory = sales_df.groupBy(\"TERRITORY\") \\\n",
    "    .agg(sum(\"SALES\").alias(\"Total_Sales\")) \\\n",
    "    .orderBy(\"TERRITORY\")\n",
    " \n",
    "sales_by_territory.show()\n",
    " \n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4996b5da-2a39-4434-b79d-70f0b524b100",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct countries: 19\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    " \n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Distinct Countries Count\") \\\n",
    "    .getOrCreate()\n",
    " \n",
    "sales_df = spark.read.csv(\"Sales.csv\", header=True, inferSchema=True)\n",
    " \n",
    "distinct_countries_count = sales_df.select(\"COUNTRY\").distinct().count()\n",
    " \n",
    "print(\"Number of distinct countries:\", distinct_countries_count)\n",
    " \n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9708647-2031-4bfe-aec4-8fc1375a68d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+\n",
      "|YEAR_ID|Max_Sales|\n",
      "+-------+---------+\n",
      "|   2003|  11279.2|\n",
      "|   2004|  12536.5|\n",
      "|   2005|  14082.8|\n",
      "+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import max\n",
    " \n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Maximum Sales by Year\") \\\n",
    "    .getOrCreate()\n",
    " \n",
    "sales_df = spark.read.csv(\"Sales.csv\", header=True, inferSchema=True)\n",
    " \n",
    "max_sales_by_year = sales_df.groupBy(\"YEAR_ID\") \\\n",
    "    .agg(max(\"SALES\").alias(\"Max_Sales\")) \\\n",
    "    .orderBy(\"YEAR_ID\")\n",
    " \n",
    "max_sales_by_year.show()\n",
    " \n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b9e0f40-12cc-49d8-9133-b36687a1611d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------+\n",
      "|YEAR_ID|        CUSTOMERNAME|Total_Quantity|\n",
      "+-------+--------------------+--------------+\n",
      "|   2003|        Royale Belge|            47|\n",
      "|   2004|Dragon Souveniers...|            28|\n",
      "|   2005|   Boards & Toys Co.|            35|\n",
      "+-------+--------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import sum, min\n",
    " \n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Customers with Least Purchases by Year\") \\\n",
    "    .getOrCreate()\n",
    " \n",
    "sales_df = spark.read.csv(\"Sales.csv\", header=True, inferSchema=True)\n",
    " \n",
    "total_quantity_by_customer_by_year = sales_df.groupBy(\"YEAR_ID\", \"CUSTOMERNAME\") \\\n",
    "    .agg(sum(\"QUANTITYORDERED\").alias(\"Total_Quantity\")) \\\n",
    "    .orderBy(\"YEAR_ID\", \"Total_Quantity\")\n",
    " \n",
    "min_quantity_by_year = total_quantity_by_customer_by_year.groupBy(\"YEAR_ID\") \\\n",
    "    .agg(min(\"Total_Quantity\").alias(\"Min_Quantity\"))\n",
    " \n",
    "customers_least_purchases_by_year = total_quantity_by_customer_by_year.alias(\"t1\").join(\n",
    "    min_quantity_by_year.alias(\"t2\"),\n",
    "    (total_quantity_by_customer_by_year[\"YEAR_ID\"] == min_quantity_by_year[\"YEAR_ID\"]) &\n",
    "    (total_quantity_by_customer_by_year[\"Total_Quantity\"] == min_quantity_by_year[\"Min_Quantity\"])\n",
    ").selectExpr(\n",
    "    \"t1.YEAR_ID as YEAR_ID\",\n",
    "    \"t1.CUSTOMERNAME as CUSTOMERNAME\",\n",
    "    \"t1.Total_Quantity as Total_Quantity\"\n",
    ")\n",
    " \n",
    "customers_least_purchases_by_year.show()\n",
    " \n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a74d92d-8f3a-4350-a9a1-9efa4b5960f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------------+------------------+\n",
      "|  COUNTRY|     STATE|          CITY|       Total_Sales|\n",
      "+---------+----------+--------------+------------------+\n",
      "|Australia|       NSW|     Chatswood|151570.98000000004|\n",
      "|Australia|       NSW|  North Sydney|153996.13000000003|\n",
      "|Australia|Queensland|South Brisbane| 59469.11999999999|\n",
      "|Australia|  Victoria|  Glen Waverly| 64591.46000000001|\n",
      "|Australia|  Victoria|     Melbourne|200995.40999999997|\n",
      "|  Austria|      NULL|          Graz|52263.899999999994|\n",
      "|  Austria|      NULL|      Salzburg|         149798.63|\n",
      "|  Belgium|      NULL|     Bruxelles|          74972.52|\n",
      "|  Belgium|      NULL|     Charleroi|           33440.1|\n",
      "|   Canada|        BC|     Tsawassen| 74634.84999999999|\n",
      "|   Canada|        BC|     Vancouver|          75238.92|\n",
      "|   Canada|    Quebec|      Montreal|          74204.79|\n",
      "|  Denmark|      NULL|       Aaarhus|100595.54999999999|\n",
      "|  Denmark|      NULL|     Kobenhavn|          145041.6|\n",
      "|  Finland|      NULL|         Espoo|113961.14999999997|\n",
      "|  Finland|      NULL|      Helsinki|111250.37999999996|\n",
      "|  Finland|      NULL|          Oulu|         104370.38|\n",
      "|   France|      NULL|         Lille|          69052.41|\n",
      "|   France|      NULL|          Lyon|142874.25000000003|\n",
      "|   France|      NULL|     Marseille|          74936.14|\n",
      "+---------+----------+--------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import sum\n",
    " \n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Sales Partitioned by Country, State, and City\") \\\n",
    "    .getOrCreate()\n",
    " \n",
    "sales_df = spark.read.csv(\"Sales.csv\", header=True, inferSchema=True)\n",
    " \n",
    "sales_partitioned = sales_df.groupBy(\"COUNTRY\", \"STATE\", \"CITY\") \\\n",
    "    .agg(sum(\"SALES\").alias(\"Total_Sales\")) \\\n",
    "    .orderBy(\"COUNTRY\", \"STATE\", \"CITY\")\n",
    " \n",
    "sales_partitioned.show()\n",
    " \n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab9890f-076f-4b89-b19a-55ccc215887f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
